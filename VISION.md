# VISION.md â€” The Meta-Layer

*Last Updated: 2026-01-30*

---

## ğŸ¯ The North Star

**Build the Maintenance Intelligence Layer for the Future**

Everything we do feeds this singular goal. Every piece of data, every interaction, every video, every training moduleâ€”all of it trains our custom industrial maintenance LLM.

---

## The Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 MAINTENANCE INTELLIGENCE LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    CUSTOM LLM (Future)                       â”‚    â”‚
â”‚  â”‚         Fine-tuned on Industrial Maintenance Domain          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â–²                                       â”‚
â”‚                              â”‚ Training Data                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              NEON VECTOR DATABASE (RAG + GraphRAG)           â”‚    â”‚
â”‚  â”‚                   Knowledge Base Layer                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â–²           â–²           â–²           â–²           â–²           â”‚
â”‚         â”‚           â”‚           â”‚           â”‚           â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ YouTube  â”‚ â”‚Industrialâ”‚ â”‚  Edge   â”‚ â”‚  CMMS   â”‚ â”‚ Jarvis  â”‚     â”‚
â”‚  â”‚ Content  â”‚ â”‚Skills Hubâ”‚ â”‚ Adapter â”‚ â”‚ Records â”‚ â”‚ Memory  â”‚     â”‚
â”‚  â”‚  (YCB)   â”‚ â”‚  (ISH)   â”‚ â”‚  (PLC)  â”‚ â”‚         â”‚ â”‚         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Streams â†’ Vector DB

**Everything gets captured:**

| Source | Data Type | Status |
|--------|-----------|--------|
| YCB v3 | Video scripts, storyboards, animations | ğŸ“‹ Resurrect |
| IndustrialSkillsHub | Curriculum, lessons, assessments | ğŸ“‹ Connect |
| Edge Adapter | PLC data, diagnostics, machine states | ğŸ”„ Building |
| CMMS | Work orders, maintenance history, assets | âœ… Live |
| Jarvis Brain | Research, decisions, conversations | âœ… Active |
| Equipment Manuals | Technical documentation | ğŸ“‹ Future |
| Customer Support | Tickets, resolutions, FAQs | ğŸ“‹ Future |

---

## Intelligence Progression

**Stepwise climb from current state to custom LLM:**

```
STEP 1 (Current)
â”œâ”€â”€ TinyLlama / Qwen 0.5B (local)
â”œâ”€â”€ Claude / Gemini (cloud)
â””â”€â”€ RAG via Neon Vector DB

STEP 2 (Next)
â”œâ”€â”€ Fine-tune 7B model (Llama 3 / Mistral)
â”œâ”€â”€ Domain: Industrial Maintenance
â”œâ”€â”€ Method: LoRA / QLoRA (parameter-efficient)
â””â”€â”€ GPU: Rented (RunPod ~$0.34-2/hr)

STEP 3 (Growth)
â”œâ”€â”€ Fine-tune larger model (13B-70B)
â”œâ”€â”€ Deeper domain specialization
â”œâ”€â”€ Add compute as data grows
â””â”€â”€ GPU: Dedicated hardware

STEP 4 (Scale)
â”œâ”€â”€ Custom pre-trained model
â”œâ”€â”€ Continuous learning pipeline
â”œâ”€â”€ Multi-modal (text + diagrams + video)
â””â”€â”€ Production deployment
```

---

## Current Priorities (Realigned)

All priorities now serve the meta-layer:

### P0: Data Capture Infrastructure
*Everything must feed the knowledge base*
- [ ] Configure all agents to log to Neon
- [ ] Set up embedding pipeline
- [ ] Create data ingestion standards

### P1: Edge Adapter
*Real-time PLC data â†’ Training data*
- [ ] Flash BeagleBone
- [ ] Deploy WireGuard
- [ ] Start capturing machine data

### P2: YouTube Content Factory
*Content generation + training data*
- [ ] Resurrect YCB v3
- [ ] Connect LLM Quality Judge
- [ ] Feed scripts â†’ Neon

### P2: Angel Funding
*Compute resources for training*
- [ ] Pitch deck focused on intelligence layer
- [ ] Highlight data moat advantage

### P3: Local LLM Infrastructure
*Stepping stone to custom model*
- [x] Ollama installed
- [x] Qwen 0.5B running
- [ ] Configure as primary for simple tasks

---

## Best Practices (AI Engineering 2025)

### Fine-Tuning Strategy
1. **Start with instruction-tuned base** (Llama 3 Instruct)
2. **Use PEFT/LoRA** â€” Train <1% of parameters
3. **Quality data > quantity** â€” Curate, don't just collect
4. **Robust evaluation** â€” Quantitative + human review
5. **Lifecycle mindset** â€” Version, monitor, retrain

### RAG + GraphRAG Architecture
1. **Neon PostgreSQL** â€” pgvector for embeddings
2. **Hybrid retrieval** â€” Vector search + knowledge graph
3. **Chunking strategy** â€” Semantic, not arbitrary
4. **Context window optimization** â€” Quality over quantity

### GPU Rental Options
| Provider | GPU | $/hour | Best For |
|----------|-----|--------|----------|
| RunPod | RTX 4090 | $0.34 | Development |
| RunPod | H100 | $1.99 | Training |
| Vast.ai | Various | Variable | Budget |
| Lambda | A100 | $0.75 | Production |

---

## The Flywheel

```
More Content â†’ More Data â†’ Better Model â†’ Better Content â†’ More Users
     â†‘                                                          â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Every piece of content we create:
1. Gets published (revenue, leads, SEO)
2. Gets embedded in vector DB (knowledge)
3. Trains the model (intelligence)
4. Makes better content (quality)

---

## Success Metrics

- **Knowledge Base Size** â€” Embeddings in Neon
- **Model Quality** â€” Evaluation benchmarks
- **Content Volume** â€” Videos/week auto-generated
- **Revenue** â€” YouTube, training platform, consulting
- **Compute Efficiency** â€” Cost per training run

---

## Constitutional Alignment

This vision follows:
- **Amendment I**: Open source first (Ollama, Llama, Neon)
- **Amendment II**: Research before building
- **Engineering Commandments**: Document everything, issue-first

---

*This document is the source of truth. All other priorities derive from it.*
